{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3802bcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\pc\\anaconda3\\lib\\site-packages (4.23.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Requirement already satisfied: idna in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: outcome in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\pc\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1985cbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7016da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver # type: ignore\n",
    "from selenium.webdriver.common.by import By # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Function to scrape job data\n",
    "def scrape_job_data():\n",
    "    # Open the Shine job search page\n",
    "    driver.get('https://www.shine.com/')\n",
    " \n",
    " # Allow time for the page to load\n",
    "    time.sleep(5)\n",
    " \n",
    " # Enter job title and location\n",
    "    job_title_field = driver.find_element(By.XPATH, '//*[@id=\"jobTitle\"]')\n",
    "    job_title_field.send_keys('Data Analyst')\n",
    " \n",
    "    location_field = driver.find_element(By.XPATH, '//*[@id=\"location\"]')\n",
    "    location_field.send_keys('Bangalore')\n",
    " \n",
    " # Click the search button\n",
    "    search_button = driver.find_element(By.XPATH, '//*[@id=\"search_button\"]')\n",
    "    search_button.click()\n",
    " \n",
    " # Allow time for the results to load\n",
    "    time.sleep(5)\n",
    " \n",
    " # Initialize lists to store the scraped data\n",
    "    job_titles = []\n",
    "    job_locations = []\n",
    "    company_names = []\n",
    "    experience_required = []\n",
    " \n",
    " # Scrape data for the first 10 job results\n",
    "    job_listings = driver.find_elements(By.XPATH, '//div[contains(@class, \"job-listing\") and position() <= 10]')\n",
    "    for job in job_listings:\n",
    "        try:\n",
    "            job_title = job.find_element(By.XPATH, './/a[contains(@class, \"job-title\")]').text\n",
    "            job_location = job.find_element(By.XPATH, './/span[contains(@class, \"location\")]').text\n",
    "            company_name = job.find_element(By.XPATH, './/a[contains(@class, \"company-name\")]').text\n",
    "            exp_required = job.find_element(By.XPATH, './/span[contains(@class, \"experience\")]').text\n",
    " \n",
    " # Append data to lists\n",
    "            job_titles.append(job_title)\n",
    "            job_locations.append(job_location)\n",
    "            company_names.append(company_name)\n",
    "            experience_required.append(exp_required)\n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f\"Error extracting data for a job listing: {e}\")\n",
    " \n",
    " # Create a DataFrame from the scraped data\n",
    "            df = pd.DataFrame({\n",
    "                'Job Title': job_titles,\n",
    "                'Location': job_locations,\n",
    "                'Company Name': company_names,\n",
    "                'Experience Required': experience_required})\n",
    " \n",
    "        return df\n",
    "\n",
    "# Main execution\n",
    "    if __name__ == \"__main__\":\n",
    "        try:\n",
    "            job_data_df = scrape_job_data()\n",
    "            print(job_data_df)\n",
    "            # Save the DataFrame to a CSV file\n",
    "            job_data_df.to_csv('job_data.csv', index=False)\n",
    "        \n",
    "        finally:\n",
    "            # Close the WebDriver\n",
    "            driver.quit()\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a3d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver # type: ignore\n",
    "from selenium.webdriver.common.by import By # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Function to scrape job data\n",
    "def scrape_job_data():\n",
    "    # Open the Shine job search page\n",
    "    driver.get('https://www.naukri.com/')\n",
    " \n",
    " # Allow time for the page to load\n",
    "    time.sleep(5)\n",
    " \n",
    " # Enter job title and location\n",
    "    job_title_field = driver.find_element(By.XPATH, '//*[@id=\"jobTitle\"]')\n",
    "    job_title_field.send_keys('â€œData Scientist')\n",
    " \n",
    "    location_field = driver.find_element(By.XPATH, '//*[@id=\"location\"]')\n",
    "    location_field.send_keys('Bangalore')\n",
    " \n",
    " # Click the search button\n",
    "    search_button = driver.find_element(By.XPATH, '//*[@id=\"search_button\"]')\n",
    "    search_button.click()\n",
    " \n",
    " # Allow time for the results to load\n",
    "    time.sleep(5)\n",
    " \n",
    " # Initialize lists to store the scraped data\n",
    "    job_titles = []\n",
    "    job_locations = []\n",
    "    company_names = []\n",
    "    experience_required = []\n",
    " \n",
    " # Scrape data for the first 10 job results\n",
    "    job_listings = driver.find_elements(By.XPATH, '//div[contains(@class, \"job-listing\") and position() <= 10]')\n",
    "    for job in job_listings:\n",
    "        try:\n",
    "            job_title = job.find_element(By.XPATH, './/a[contains(@class, \"job-title\")]').text\n",
    "            job_location = job.find_element(By.XPATH, './/span[contains(@class, \"location\")]').text\n",
    "            company_name = job.find_element(By.XPATH, './/a[contains(@class, \"company-name\")]').text\n",
    "            exp_required = job.find_element(By.XPATH, './/span[contains(@class, \"experience\")]').text\n",
    " \n",
    " # Append data to lists\n",
    "            job_titles.append(job_title)\n",
    "            job_locations.append(job_location)\n",
    "            company_names.append(company_name)\n",
    "            experience_required.append(exp_required)\n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f\"Error extracting data for a job listing: {e}\")\n",
    " \n",
    " # Create a DataFrame from the scraped data\n",
    "            df = pd.DataFrame({\n",
    "                'Job Title': job_titles,\n",
    "                'Location': job_locations,\n",
    "                'Company Name': company_names,\n",
    "                'Experience Required': experience_required})\n",
    " \n",
    "        return df\n",
    "\n",
    "# Main execution\n",
    "    if __name__ == \"__main__\":\n",
    "        try:\n",
    "            job_data_df = scrape_job_data()\n",
    "            print(job_data_df)\n",
    "            # Save the DataFrame to a CSV file\n",
    "            job_data_df.to_csv('job_data.csv', index=False)\n",
    "        \n",
    "        finally:\n",
    "            # Close the WebDriver\n",
    "            driver.quit()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471989e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec868d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba4facbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "No more pages available.\n",
      "Scraping completed. Data saved to sunglasses_data.csv.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Setup webdriver (Make sure to download the correct version for your browser)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open Flipkart website\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Close the login popup if it appears\n",
    "try:\n",
    "    close_popup = driver.find_element(By.XPATH, \"//button[contains(text(),'âœ•')]\")\n",
    "    close_popup.click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Search for sunglasses\n",
    "search_box = driver.find_element(By.NAME, \"q\")\n",
    "search_box.send_keys(\"sunglasses\")\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "time.sleep(3)\n",
    "\n",
    "# Function to scrape data from a single page\n",
    "def scrape_page():\n",
    "    products = driver.find_elements(By.XPATH, \"//div[contains(@class,'_2B099V')]\")\n",
    "    data = []\n",
    "    for product in products:\n",
    "        try:\n",
    "            brand = product.find_element(By.XPATH, \".//div[contains(@class,'_2WkVRV')]\").text\n",
    "        except:\n",
    "            brand = None\n",
    "        \n",
    "        try:\n",
    "            description = product.find_element(By.XPATH, \".//a[contains(@class,'IRpwTa')]\").text\n",
    "        except:\n",
    "            description = None\n",
    "        \n",
    "        try:\n",
    "            price = product.find_element(By.XPATH, \".//div[contains(@class,'_30jeq3')]\").text\n",
    "        except:\n",
    "            price = None\n",
    "\n",
    "        data.append({\n",
    "            'Brand': brand,\n",
    "            'ProductDescription': description,\n",
    "            'Price': price\n",
    "        })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Initialize data storage\n",
    "sunglasses_data = []\n",
    "page = 1\n",
    "max_items = 100\n",
    "\n",
    "# Loop through pages and scrape until we reach 100 items\n",
    "while len(sunglasses_data) < max_items:\n",
    "    \n",
    "    print(f\"Scraping page {page}...\")\n",
    "    sunglasses_data.extend(scrape_page())\n",
    "    \n",
    "    # Stop if we have enough data\n",
    "    if len(sunglasses_data) >= max_items:\n",
    "        break\n",
    "    \n",
    "    # Click on the next button to go to the next page\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, \"//a[@class='_1LKTO3' and text()='Next']\")\n",
    "        next_button.click()\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        print(\"No more pages available.\")\n",
    "        break\n",
    "\n",
    "    page += 1\n",
    "\n",
    "# Trim the data if it exceeds 100 items\n",
    "sunglasses_data = sunglasses_data[:100]\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(sunglasses_data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('sunglasses_data.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed. Data saved to sunglasses_data.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bd991d",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "Ass 2 WEbscrapping Selenium 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b9565d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=128.0.6613.120)\nStacktrace:\n\tGetHandleVerifier [0x00007FF639A7B5D2+29090]\n\t(No symbol) [0x00007FF6399EE689]\n\t(No symbol) [0x00007FF6398AB1CA]\n\t(No symbol) [0x00007FF63987FAF5]\n\t(No symbol) [0x00007FF63992E2E7]\n\t(No symbol) [0x00007FF639945EE1]\n\t(No symbol) [0x00007FF639926493]\n\t(No symbol) [0x00007FF6398F09B1]\n\t(No symbol) [0x00007FF6398F1B11]\n\tGetHandleVerifier [0x00007FF639D98C5D+3295277]\n\tGetHandleVerifier [0x00007FF639DE4843+3605523]\n\tGetHandleVerifier [0x00007FF639DDA707+3564247]\n\tGetHandleVerifier [0x00007FF639B36EB6+797318]\n\t(No symbol) [0x00007FF6399F980F]\n\t(No symbol) [0x00007FF6399F53F4]\n\t(No symbol) [0x00007FF6399F5580]\n\t(No symbol) [0x00007FF6399E4A1F]\n\tBaseThreadInitThunk [0x00007FF8CF8A7374+20]\n\tRtlUserThreadStart [0x00007FF8D12FCC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_724\\2854000567.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Enter \"Data Scientist\" in the search field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0msearch_field\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"//input[@class='suggestor-input ']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0msearch_field\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data Scientist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'[name=\"{value}\"]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=128.0.6613.120)\nStacktrace:\n\tGetHandleVerifier [0x00007FF639A7B5D2+29090]\n\t(No symbol) [0x00007FF6399EE689]\n\t(No symbol) [0x00007FF6398AB1CA]\n\t(No symbol) [0x00007FF63987FAF5]\n\t(No symbol) [0x00007FF63992E2E7]\n\t(No symbol) [0x00007FF639945EE1]\n\t(No symbol) [0x00007FF639926493]\n\t(No symbol) [0x00007FF6398F09B1]\n\t(No symbol) [0x00007FF6398F1B11]\n\tGetHandleVerifier [0x00007FF639D98C5D+3295277]\n\tGetHandleVerifier [0x00007FF639DE4843+3605523]\n\tGetHandleVerifier [0x00007FF639DDA707+3564247]\n\tGetHandleVerifier [0x00007FF639B36EB6+797318]\n\t(No symbol) [0x00007FF6399F980F]\n\t(No symbol) [0x00007FF6399F53F4]\n\t(No symbol) [0x00007FF6399F5580]\n\t(No symbol) [0x00007FF6399E4A1F]\n\tBaseThreadInitThunk [0x00007FF8CF8A7374+20]\n\tRtlUserThreadStart [0x00007FF8D12FCC91+33]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Setup the webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the Naukri website\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Enter \"Data Scientist\" in the search field\n",
    "search_field = driver.find_element(By.XPATH, \"//input[@class='suggestor-input ']\")\n",
    "search_field.send_keys(\"Data Scientist\")\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "search_button = driver.find_element(By.XPATH, '//*[@id=\"search_button\"]')\n",
    "search_button.click()\n",
    " \n",
    "# Apply the \"Delhi/NCR\" location filter\n",
    "location_filter = driver.find_element(By.XPATH, \"//label[contains(text(), 'Delhi / NCR')]\")\n",
    "location_filter.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Apply the \"3-6 Lakhs\" salary filter\n",
    "salary_filter = driver.find_element(By.XPATH, \"//label[contains(text(), '3-6 Lakhs')]\")\n",
    "salary_filter.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Function to scrape data from a single page\n",
    "def scrape_jobs():\n",
    "    \n",
    "    jobs = driver.find_elements(By.XPATH, \"//article[@class='jobTuple bgWhite br4 mb-8']\")\n",
    "    job_data = []\n",
    "    for job in jobs[:10]:  # Limit to first 10 jobs\n",
    "        try:\n",
    "            title = job.find_element(By.XPATH, \".//a[@class='title fw500 ellipsis']\").text\n",
    "        except:\n",
    "            title = None\n",
    "\n",
    "        try:\n",
    "            location = job.find_element(By.XPATH, \".//li[@class='fleft grey-text br2 placeHolderLi location']/span\").text\n",
    "        except:\n",
    "            location = None\n",
    "\n",
    "        try:\n",
    "            company = job.find_element(By.XPATH, \".//a[@class='subTitle ellipsis fleft']\").text\n",
    "        except:\n",
    "            company = None\n",
    "\n",
    "        try:\n",
    "            experience = job.find_element(By.XPATH, \".//li[@class='fleft grey-text br2 placeHolderLi experience']/span\").text\n",
    "        except:\n",
    "            experience = None\n",
    "\n",
    "        job_data.append({\n",
    "            'Job Title': title,\n",
    "            'Location': location,\n",
    "            'Company': company,\n",
    "            'Experience Required': experience\n",
    "        })\n",
    "    return job_data\n",
    "\n",
    "# Scrape job data\n",
    "job_listings = scrape_jobs()\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame using pandas\n",
    "df = pd.DataFrame(job_listings)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv('naukri_data_scientist_jobs.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed. Data saved to naukri_data_scientist_jobs.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e2851e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64abea28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//input[@id='id_q']\"}\n  (Session info: chrome=128.0.6613.120); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF61CD1B5D2+29090]\n\t(No symbol) [0x00007FF61CC8E689]\n\t(No symbol) [0x00007FF61CB4B1CA]\n\t(No symbol) [0x00007FF61CB9EFD7]\n\t(No symbol) [0x00007FF61CB9F22C]\n\t(No symbol) [0x00007FF61CBE97F7]\n\t(No symbol) [0x00007FF61CBC672F]\n\t(No symbol) [0x00007FF61CBE65D9]\n\t(No symbol) [0x00007FF61CBC6493]\n\t(No symbol) [0x00007FF61CB909B1]\n\t(No symbol) [0x00007FF61CB91B11]\n\tGetHandleVerifier [0x00007FF61D038C5D+3295277]\n\tGetHandleVerifier [0x00007FF61D084843+3605523]\n\tGetHandleVerifier [0x00007FF61D07A707+3564247]\n\tGetHandleVerifier [0x00007FF61CDD6EB6+797318]\n\t(No symbol) [0x00007FF61CC9980F]\n\t(No symbol) [0x00007FF61CC953F4]\n\t(No symbol) [0x00007FF61CC95580]\n\t(No symbol) [0x00007FF61CC84A1F]\n\tBaseThreadInitThunk [0x00007FF8CF8A7374+20]\n\tRtlUserThreadStart [0x00007FF8D12FCC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10868\\3206742642.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Enter \"Data Scientist\" in the Job title, Skills field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mjob_title_field\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"//input[@id='id_q']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mjob_title_field\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data Scientist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'[name=\"{value}\"]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//input[@id='id_q']\"}\n  (Session info: chrome=128.0.6613.120); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF61CD1B5D2+29090]\n\t(No symbol) [0x00007FF61CC8E689]\n\t(No symbol) [0x00007FF61CB4B1CA]\n\t(No symbol) [0x00007FF61CB9EFD7]\n\t(No symbol) [0x00007FF61CB9F22C]\n\t(No symbol) [0x00007FF61CBE97F7]\n\t(No symbol) [0x00007FF61CBC672F]\n\t(No symbol) [0x00007FF61CBE65D9]\n\t(No symbol) [0x00007FF61CBC6493]\n\t(No symbol) [0x00007FF61CB909B1]\n\t(No symbol) [0x00007FF61CB91B11]\n\tGetHandleVerifier [0x00007FF61D038C5D+3295277]\n\tGetHandleVerifier [0x00007FF61D084843+3605523]\n\tGetHandleVerifier [0x00007FF61D07A707+3564247]\n\tGetHandleVerifier [0x00007FF61CDD6EB6+797318]\n\t(No symbol) [0x00007FF61CC9980F]\n\t(No symbol) [0x00007FF61CC953F4]\n\t(No symbol) [0x00007FF61CC95580]\n\t(No symbol) [0x00007FF61CC84A1F]\n\tBaseThreadInitThunk [0x00007FF8CF8A7374+20]\n\tRtlUserThreadStart [0x00007FF8D12FCC91+33]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Setup the webdriver (Make sure to download the correct WebDriver for your browser)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the Shine.com website\n",
    "driver.get(\"https://www.shine.com/\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Enter \"Data Scientist\" in the Job title, Skills field\n",
    "job_title_field = driver.find_element(By.XPATH, \"//input[@id='id_q']\")\n",
    "job_title_field.send_keys(\"Data Scientist\")\n",
    "\n",
    "# Enter \"Bangalore\" in the location field\n",
    "location_field = driver.find_element(By.XPATH, \"//input[@id='id_loc']\")\n",
    "location_field.send_keys(\"Bangalore\")\n",
    "\n",
    "# Click the search button\n",
    "search_button = driver.find_element(By.XPATH, \"//button[@class='btn btn-primary']\")\n",
    "search_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# Function to scrape job data\n",
    "def scrape_jobs():\n",
    "    jobs = driver.find_elements(By.XPATH, \"//div[@class='w-90']/div[@class='card-search']\")\n",
    "    job_data = []\n",
    "    for job in jobs[:10]:  # Scrape only first 10 job results\n",
    "        try:\n",
    "            title = job.find_element(By.XPATH, \".//h2/a\").text\n",
    "        except:\n",
    "            title = None\n",
    "\n",
    "        try:\n",
    "            location = job.find_element(By.XPATH, \".//ul[@class='list-unstyled mt-2']/li[2]/span\").text\n",
    "        except:\n",
    "            location = None\n",
    "\n",
    "        try:\n",
    "            company = job.find_element(By.XPATH, \".//div[@class='d-flex justify-content-between']/div[1]/h3\").text\n",
    "        except:\n",
    "            company = None\n",
    "\n",
    "        try:\n",
    "            experience = job.find_element(By.XPATH, \".//ul[@class='list-unstyled mt-2']/li[1]/span\").text\n",
    "        except:\n",
    "            experience = None\n",
    "\n",
    "        job_data.append({\n",
    "            'Job Title': title,\n",
    "            'Location': location,\n",
    "            'Company': company,\n",
    "            'Experience Required': experience\n",
    "        })\n",
    "    return job_data\n",
    "\n",
    "# Scrape job data\n",
    "job_listings = scrape_jobs()\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame using pandas\n",
    "df = pd.DataFrame(job_listings)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv('shine_data_scientist_jobs_bangalore.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed. Data saved to shine_data_scientist_jobs_bangalore.csv.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530a9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bffe7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "No more pages available.\n",
      "Scraping completed. Data saved to flipkart_iphone11_reviews.csv.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Setup the webdriver (Make sure to download the correct WebDriver for your browser)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the Flipkart iPhone 11 reviews page\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Function to scrape review data from a single page\n",
    "def scrape_reviews():\n",
    "    reviews = driver.find_elements(By.XPATH, \"//div[@class='_1AtVbE']\")\n",
    "    review_data = []\n",
    "    for review in reviews:\n",
    "        try:\n",
    "            rating = review.find_element(By.XPATH, \".//div[@class='_3LWZlK _1BLPMq']\").text\n",
    "        except:\n",
    "            rating = None\n",
    "\n",
    "        try:\n",
    "            review_summary = review.find_element(By.XPATH, \".//p[@class='_2-N8zT']\").text\n",
    "        except:\n",
    "            review_summary = None\n",
    "\n",
    "        try:\n",
    "            full_review = review.find_element(By.XPATH, \".//div[@class='t-ZTKy']/div/div\").text\n",
    "        except:\n",
    "            full_review = None\n",
    "\n",
    "        if rating and review_summary and full_review:\n",
    "            review_data.append({\n",
    "                'Rating': rating,\n",
    "                'Review Summary': review_summary,\n",
    "                'Full Review': full_review\n",
    "            })\n",
    "    return review_data\n",
    "\n",
    "# Initialize data storage\n",
    "all_reviews = []\n",
    "max_reviews = 100\n",
    "page = 1\n",
    "\n",
    "# Loop through pages and scrape until we have 100 reviews\n",
    "while len(all_reviews) < max_reviews:\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    all_reviews.extend(scrape_reviews())\n",
    "    \n",
    "    # Stop if we have collected enough reviews\n",
    "    if len(all_reviews) >= max_reviews:\n",
    "        break\n",
    "\n",
    "    # Click on the \"Next\" button to go to the next page\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, \"//a[@class='_1LKTO3' and text()='Next']\")\n",
    "        next_button.click()\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        print(\"No more pages available.\")\n",
    "        break\n",
    "\n",
    "    page += 1\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Trim the data to 100 reviews\n",
    "all_reviews = all_reviews[:max_reviews]\n",
    "\n",
    "# Convert the data to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_reviews)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv('flipkart_iphone11_reviews.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed. Data saved to flipkart_iphone11_reviews.csv.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da395c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d8a39cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[name=\"q\"]\"}\n  (Session info: chrome=128.0.6613.120); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF61CD1B5D2+29090]\n\t(No symbol) [0x00007FF61CC8E689]\n\t(No symbol) [0x00007FF61CB4B1CA]\n\t(No symbol) [0x00007FF61CB9EFD7]\n\t(No symbol) [0x00007FF61CB9F22C]\n\t(No symbol) [0x00007FF61CBE97F7]\n\t(No symbol) [0x00007FF61CBC672F]\n\t(No symbol) [0x00007FF61CBE65D9]\n\t(No symbol) [0x00007FF61CBC6493]\n\t(No symbol) [0x00007FF61CB909B1]\n\t(No symbol) [0x00007FF61CB91B11]\n\tGetHandleVerifier [0x00007FF61D038C5D+3295277]\n\tGetHandleVerifier [0x00007FF61D084843+3605523]\n\tGetHandleVerifier [0x00007FF61D07A707+3564247]\n\tGetHandleVerifier [0x00007FF61CDD6EB6+797318]\n\t(No symbol) [0x00007FF61CC9980F]\n\t(No symbol) [0x00007FF61CC953F4]\n\t(No symbol) [0x00007FF61CC95580]\n\t(No symbol) [0x00007FF61CC84A1F]\n\tBaseThreadInitThunk [0x00007FF8CF8A7374+20]\n\tRtlUserThreadStart [0x00007FF8D12FCC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10868\\1719011266.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Enter \"sneakers\" in the search field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0msearch_box\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"q\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0msearch_box\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sneakers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0msearch_box\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"//button[@type='submit']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'[name=\"{value}\"]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[name=\"q\"]\"}\n  (Session info: chrome=128.0.6613.120); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF61CD1B5D2+29090]\n\t(No symbol) [0x00007FF61CC8E689]\n\t(No symbol) [0x00007FF61CB4B1CA]\n\t(No symbol) [0x00007FF61CB9EFD7]\n\t(No symbol) [0x00007FF61CB9F22C]\n\t(No symbol) [0x00007FF61CBE97F7]\n\t(No symbol) [0x00007FF61CBC672F]\n\t(No symbol) [0x00007FF61CBE65D9]\n\t(No symbol) [0x00007FF61CBC6493]\n\t(No symbol) [0x00007FF61CB909B1]\n\t(No symbol) [0x00007FF61CB91B11]\n\tGetHandleVerifier [0x00007FF61D038C5D+3295277]\n\tGetHandleVerifier [0x00007FF61D084843+3605523]\n\tGetHandleVerifier [0x00007FF61D07A707+3564247]\n\tGetHandleVerifier [0x00007FF61CDD6EB6+797318]\n\t(No symbol) [0x00007FF61CC9980F]\n\t(No symbol) [0x00007FF61CC953F4]\n\t(No symbol) [0x00007FF61CC95580]\n\t(No symbol) [0x00007FF61CC84A1F]\n\tBaseThreadInitThunk [0x00007FF8CF8A7374+20]\n\tRtlUserThreadStart [0x00007FF8D12FCC91+33]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Setup the webdriver (Make sure to download the correct WebDriver for your browser)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the Flipkart homepage\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Close the login popup if it appears\n",
    "try:\n",
    "    close_popup = driver.find_element(By.XPATH, \"//button[contains(text(),'âœ•')]\")\n",
    "    close_popup.click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Enter \"sneakers\" in the search field\n",
    "search_box = driver.find_element(By.NAME, \"q\")\n",
    "search_box.send_keys(\"sneakers\")\n",
    "search_box.send_keys(By.XPATH, \"//button[@type='submit']\").click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "\n",
    "# Function to scrape sneakers data from a single page\n",
    "def scrape_sneakers():\n",
    "    \n",
    "    products = driver.find_elements(By.XPATH, \"//div[@class='_1AtVbE']\")\n",
    "    sneakers_data = []\n",
    "    \n",
    "    for product in products:\n",
    "        \n",
    "        try:\n",
    "            brand = product.find_element(By.XPATH, \".//div[@class='_2WkVRV']\").text\n",
    "        except:\n",
    "            brand = None\n",
    "        \n",
    "        try:\n",
    "            description = product.find_element(By.XPATH, \".//a[@class='IRpwTa']\").text\n",
    "        except:\n",
    "            description = None\n",
    "\n",
    "        try:\n",
    "            price = product.find_element(By.XPATH, \".//div[@class='_30jeq3']\").text\n",
    "        except:\n",
    "            price = None\n",
    "\n",
    "        if brand and description and price:\n",
    "            sneakers_data.append({\n",
    "                'Brand': brand,\n",
    "                'ProductDescription': description,\n",
    "                'Price': price\n",
    "            })\n",
    "    return sneakers_data\n",
    "\n",
    "# Initialize storage for sneakers data\n",
    "all_sneakers = []\n",
    "page = 1\n",
    "max_items = 100\n",
    "\n",
    "# Loop through pages and scrape until we get 100 sneakers\n",
    "while len(all_sneakers) < max_items:\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    all_sneakers.extend(scrape_sneakers())\n",
    "    \n",
    "    # Stop if we have enough data\n",
    "    if len(all_sneakers) >= max_items:\n",
    "        break\n",
    "    \n",
    "    # Click on the \"Next\" button to go to the next page\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, \"//a[@class='_1LKTO3' and text()='Next']\")\n",
    "        next_button.click()\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        print(\"No more pages available.\")\n",
    "        break\n",
    "\n",
    "    page += 1\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Trim the data to 100 sneakers\n",
    "all_sneakers = all_sneakers[:max_items]\n",
    "\n",
    "# Convert the scraped data into a pandas DataFrame\n",
    "df = pd.DataFrame(all_sneakers)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv('flipkart_sneakers.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed. Data saved to flipkart_sneakers.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608e6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d5a6de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping completed. Data saved to amazon_laptops.csv.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Setup the WebDriver (Make sure to download the correct WebDriver for your browser)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the Amazon.in website\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Enter \"Laptop\" in the search field\n",
    "search_box = driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "search_box.send_keys(\"Laptop\")\n",
    "search_box.submit()  # Submit the search form\n",
    "time.sleep(5)\n",
    "\n",
    "# Apply the CPU Type filter for \"Intel Core i7\"\n",
    "# Scroll down to load the filter section\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight/2);\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Find and click the \"Intel Core i7\" filter checkbox\n",
    "cpu_filter = driver.find_element(By.XPATH, \"//li[@aria-label='Intel Core i7']//i[@class='a-icon a-icon-checkbox']\")\n",
    "cpu_filter.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# Function to scrape laptop data\n",
    "def scrape_laptops():\n",
    "    laptops = driver.find_elements(By.XPATH, \"//div[@data-component-type='s-search-result']\")\n",
    "    laptop_data = []\n",
    "    for laptop in laptops[:10]:  # Only scrape the first 10 laptops\n",
    "        try:\n",
    "            title = laptop.find_element(By.XPATH, \".//h2/a/span\").text\n",
    "        except:\n",
    "            title = None\n",
    "\n",
    "        try:\n",
    "            rating = laptop.find_element(By.XPATH, \".//span[@class='a-icon-alt']\").text\n",
    "        except:\n",
    "            rating = None\n",
    "\n",
    "        try:\n",
    "            price = laptop.find_element(By.XPATH, \".//span[@class='a-price-whole']\").text\n",
    "        except:\n",
    "            price = None\n",
    "\n",
    "        laptop_data.append({\n",
    "            'Title': title,\n",
    "            'Rating': rating,\n",
    "            'Price': price\n",
    "        })\n",
    "    return laptop_data\n",
    "\n",
    "# Scrape the data for the first 10 laptops\n",
    "laptops = scrape_laptops()\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Convert the data to a Pandas DataFrame\n",
    "df = pd.DataFrame(laptops)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv('amazon_laptops.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed. Data saved to amazon_laptops.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dcfbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f280453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5d3ce56",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"link text\",\"selector\":\"Top Quotes\"}\n  (Session info: chrome=128.0.6613.120); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF61CD1B5D2+29090]\n\t(No symbol) [0x00007FF61CC8E689]\n\t(No symbol) [0x00007FF61CB4B1CA]\n\t(No symbol) [0x00007FF61CB9EFD7]\n\t(No symbol) [0x00007FF61CB9F22C]\n\t(No symbol) [0x00007FF61CBE97F7]\n\t(No symbol) [0x00007FF61CBC672F]\n\t(No symbol) [0x00007FF61CBE65D9]\n\t(No symbol) [0x00007FF61CBC6493]\n\t(No symbol) [0x00007FF61CB909B1]\n\t(No symbol) [0x00007FF61CB91B11]\n\tGetHandleVerifier [0x00007FF61D038C5D+3295277]\n\tGetHandleVerifier [0x00007FF61D084843+3605523]\n\tGetHandleVerifier [0x00007FF61D07A707+3564247]\n\tGetHandleVerifier [0x00007FF61CDD6EB6+797318]\n\t(No symbol) [0x00007FF61CC9980F]\n\t(No symbol) [0x00007FF61CC953F4]\n\t(No symbol) [0x00007FF61CC95580]\n\t(No symbol) [0x00007FF61CC84A1F]\n\tBaseThreadInitThunk [0x00007FF8CF8A7374+20]\n\tRtlUserThreadStart [0x00007FF8D12FCC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10868\\503566214.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Click on the \"Top Quotes\" section\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtop_quotes_link\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLINK_TEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Top Quotes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mtop_quotes_link\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'[name=\"{value}\"]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"link text\",\"selector\":\"Top Quotes\"}\n  (Session info: chrome=128.0.6613.120); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF61CD1B5D2+29090]\n\t(No symbol) [0x00007FF61CC8E689]\n\t(No symbol) [0x00007FF61CB4B1CA]\n\t(No symbol) [0x00007FF61CB9EFD7]\n\t(No symbol) [0x00007FF61CB9F22C]\n\t(No symbol) [0x00007FF61CBE97F7]\n\t(No symbol) [0x00007FF61CBC672F]\n\t(No symbol) [0x00007FF61CBE65D9]\n\t(No symbol) [0x00007FF61CBC6493]\n\t(No symbol) [0x00007FF61CB909B1]\n\t(No symbol) [0x00007FF61CB91B11]\n\tGetHandleVerifier [0x00007FF61D038C5D+3295277]\n\tGetHandleVerifier [0x00007FF61D084843+3605523]\n\tGetHandleVerifier [0x00007FF61D07A707+3564247]\n\tGetHandleVerifier [0x00007FF61CDD6EB6+797318]\n\t(No symbol) [0x00007FF61CC9980F]\n\t(No symbol) [0x00007FF61CC953F4]\n\t(No symbol) [0x00007FF61CC95580]\n\t(No symbol) [0x00007FF61CC84A1F]\n\tBaseThreadInitThunk [0x00007FF8CF8A7374+20]\n\tRtlUserThreadStart [0x00007FF8D12FCC91+33]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Setup the webdriver (Make sure to download the correct WebDriver for your browser)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the AZQuotes website\n",
    "driver.get(\"https://www.azquotes.com/\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Click on the \"Top Quotes\" section\n",
    "top_quotes_link = driver.find_element(By.LINK_TEXT, \"Top Quotes\")\n",
    "top_quotes_link.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Function to scrape quotes data from a single page\n",
    "def scrape_quotes():\n",
    "    quotes_elements = driver.find_elements(By.XPATH, \"//div[@class='wrap-block']\")\n",
    "    quotes_data = []\n",
    "    for quote_element in quotes_elements:\n",
    "        try:\n",
    "            quote = quote_element.find_element(By.CLASS_NAME, \"title\").text\n",
    "        except:\n",
    "            quote = None\n",
    "        \n",
    "        try:\n",
    "            author = quote_element.find_element(By.CLASS_NAME, \"author\").text\n",
    "        except:\n",
    "            author = None\n",
    "        \n",
    "        try:\n",
    "            type_of_quote = quote_element.find_element(By.CLASS_NAME, \"tags\").text\n",
    "        except:\n",
    "            type_of_quote = None\n",
    "\n",
    "        if quote and author and type_of_quote:\n",
    "            quotes_data.append({\n",
    "                'Quote': quote,\n",
    "                'Author': author,\n",
    "                'Type of Quote': type_of_quote\n",
    "            })\n",
    "    return quotes_data\n",
    "\n",
    "# Initialize storage for quotes data\n",
    "all_quotes = []\n",
    "page = 1\n",
    "max_quotes = 1000\n",
    "\n",
    "# Loop through the pages and scrape data\n",
    "while len(all_quotes) < max_quotes:\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    all_quotes.extend(scrape_quotes())\n",
    "    \n",
    "    # Stop if we have collected enough quotes\n",
    "    if len(all_quotes) >= max_quotes:\n",
    "        break\n",
    "    \n",
    "    # Click on the \"Next\" button to go to the next page\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, \"//li[@class='next']/a\")\n",
    "        next_button.click()\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        print(\"No more pages available.\")\n",
    "        break\n",
    "\n",
    "    page += 1\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Trim the data to 1000 quotes\n",
    "all_quotes = all_quotes[:max_quotes]\n",
    "\n",
    "# Convert the data to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_quotes)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv('top_1000_quotes.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed. Data saved to top_1000_quotes.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd78230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733f0a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df4f938e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//table[@class='table table-bordered']\"}\n  (Session info: chrome=128.0.6613.120); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF61CD1B5D2+29090]\n\t(No symbol) [0x00007FF61CC8E689]\n\t(No symbol) [0x00007FF61CB4B1CA]\n\t(No symbol) [0x00007FF61CB9EFD7]\n\t(No symbol) [0x00007FF61CB9F22C]\n\t(No symbol) [0x00007FF61CBE97F7]\n\t(No symbol) [0x00007FF61CBC672F]\n\t(No symbol) [0x00007FF61CBE65D9]\n\t(No symbol) [0x00007FF61CBC6493]\n\t(No symbol) [0x00007FF61CB909B1]\n\t(No symbol) [0x00007FF61CB91B11]\n\tGetHandleVerifier [0x00007FF61D038C5D+3295277]\n\tGetHandleVerifier [0x00007FF61D084843+3605523]\n\tGetHandleVerifier [0x00007FF61D07A707+3564247]\n\tGetHandleVerifier [0x00007FF61CDD6EB6+797318]\n\t(No symbol) [0x00007FF61CC9980F]\n\t(No symbol) [0x00007FF61CC953F4]\n\t(No symbol) [0x00007FF61CC95580]\n\t(No symbol) [0x00007FF61CC84A1F]\n\tBaseThreadInitThunk [0x00007FF8CF8A7374+20]\n\tRtlUserThreadStart [0x00007FF8D12FCC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10868\\840719359.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# Scrape the prime ministers' data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mprime_ministers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscrape_prime_ministers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# Close the browser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10868\\840719359.py\u001b[0m in \u001b[0;36mscrape_prime_ministers\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mscrape_prime_ministers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Find the table that contains the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"//table[@class='table table-bordered']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTAG_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Skip the header row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'[name=\"{value}\"]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//table[@class='table table-bordered']\"}\n  (Session info: chrome=128.0.6613.120); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF61CD1B5D2+29090]\n\t(No symbol) [0x00007FF61CC8E689]\n\t(No symbol) [0x00007FF61CB4B1CA]\n\t(No symbol) [0x00007FF61CB9EFD7]\n\t(No symbol) [0x00007FF61CB9F22C]\n\t(No symbol) [0x00007FF61CBE97F7]\n\t(No symbol) [0x00007FF61CBC672F]\n\t(No symbol) [0x00007FF61CBE65D9]\n\t(No symbol) [0x00007FF61CBC6493]\n\t(No symbol) [0x00007FF61CB909B1]\n\t(No symbol) [0x00007FF61CB91B11]\n\tGetHandleVerifier [0x00007FF61D038C5D+3295277]\n\tGetHandleVerifier [0x00007FF61D084843+3605523]\n\tGetHandleVerifier [0x00007FF61D07A707+3564247]\n\tGetHandleVerifier [0x00007FF61CDD6EB6+797318]\n\t(No symbol) [0x00007FF61CC9980F]\n\t(No symbol) [0x00007FF61CC953F4]\n\t(No symbol) [0x00007FF61CC95580]\n\t(No symbol) [0x00007FF61CC84A1F]\n\tBaseThreadInitThunk [0x00007FF8CF8A7374+20]\n\tRtlUserThreadStart [0x00007FF8D12FCC91+33]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Setup the webdriver (Make sure to download the correct WebDriver for your browser)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the Jagran Josh website\n",
    "driver.get(\"https://www.jagranjosh.com/general-knowledge/list-of-all-prime-ministers-of-india-1473165149-1\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Function to scrape data for Prime Ministers\n",
    "def scrape_prime_ministers():\n",
    "    # Find the table that contains the data\n",
    "    table = driver.find_element(By.XPATH, \"//table[@class='table table-bordered']\")\n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")[1:]  # Skip the header row\n",
    "    \n",
    "    pm_data = []\n",
    "    \n",
    "    for row in rows:\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        \n",
    "        # Extract relevant data\n",
    "        name = columns[0].text\n",
    "        born_dead = columns[1].text\n",
    "        term_of_office = columns[2].text\n",
    "        remarks = columns[3].text\n",
    "        \n",
    "        pm_data.append({\n",
    "            'Name': name,\n",
    "            'Born-Dead': born_dead,\n",
    "            'Term of Office': term_of_office,\n",
    "            'Remarks': remarks\n",
    "        })\n",
    "    \n",
    "    return pm_data\n",
    "\n",
    "# Scrape the prime ministers' data\n",
    "prime_ministers = scrape_prime_ministers()\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Convert the data into a Pandas DataFrame\n",
    "df = pd.DataFrame(prime_ministers)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('prime_ministers_of_india.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed. Data saved to prime_ministers_of_india.csv.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75cef7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2820cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b6c32c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Setup the WebDriver (Make sure to download the correct WebDriver for your browser)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the Motor1 website\n",
    "driver.get(\"https://www.motor1.com/\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Find the search bar, type '50 most expensive cars' and submit the search\n",
    "search_box = driver.find_element(By.ID, \"gsc-i-id1\")\n",
    "search_box.send_keys(\"50 most expensive cars\")\n",
    "search_box.submit()\n",
    "time.sleep(3)\n",
    "\n",
    "# Click on the relevant search result (ensure it's the right one for '50 most expensive cars in the world')\n",
    "# It might vary, so the XPath should be updated based on the search result position\n",
    "result_link = driver.find_element(By.XPATH, \"//a[contains(text(), '50 Most Expensive Cars')]\")\n",
    "result_link.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Scrape the car names and prices\n",
    "car_data = []\n",
    "\n",
    "# Assuming the article lists cars in a structure like: <h2> for car name and <p> for price\n",
    "cars = driver.find_elements(By.XPATH, \"//h2\")  # Locate car names\n",
    "prices = driver.find_elements(By.XPATH, \"//p\")  # Locate car prices (may need refinement based on site structure)\n",
    "\n",
    "# Extracting data (assuming prices are next to car names)\n",
    "for car, price in zip(cars, prices[:50]):  # Limit to 50 most expensive cars\n",
    "    car_name = car.text.strip()\n",
    "    car_price = price.text.strip()\n",
    "    car_data.append({\n",
    "        'Car Name': car_name,\n",
    "        'Price': car_price\n",
    "    })\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Convert the data into a Pandas DataFrame\n",
    "df = pd.DataFrame(car_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('most_expensive_cars.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed. Data saved to most_expensive_cars.csv.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f96077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
